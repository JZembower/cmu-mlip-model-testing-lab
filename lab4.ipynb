{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3fcf777d",
      "metadata": {},
      "source": [
        "You are evaluating a candidate sentiment model to replace a production baseline. Your goal is to determine whether this model should ship.\n",
        "\n",
        "‚ÄúShip‚Äù means: we would choose the candidate model over the baseline for deployment based on the evidence you collect."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76cfc1c7",
      "metadata": {},
      "source": [
        "### Step 1 - Install the required dependencies, set up W&B and make sure the python version is 3.10 and above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e1012c63",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import wandb\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "01639808",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "4f18b443",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.14.0\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5b8e44d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "#imports and config:\n",
        "import re, regex, emoji\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "\n",
        "\n",
        "# WANDB CONFIG\n",
        "PROJECT = \"mlip-lab4-slices-2026\"\n",
        "ENTITY = None\n",
        "RUN_NAME = \"baseline_vs_candidate\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a3a6beee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Models to compare\n",
        "MODELS = {\n",
        "    \"baseline_model\": \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
        "    \"candidate_model\":    \"LYTinn/finetuning-sentiment-model-tweet-gpt2\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "434c2156",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label normalization for tweet_eval (0/1/2 -> string labels)\n",
        "ID2LABEL = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "\n",
        "# Many HF sentiment models output labels like LABEL_0 / LABEL_1 / LABEL_2\n",
        "HF_LABEL_MAP = {\"LABEL_0\": \"negative\", \"LABEL_1\": \"neutral\", \"LABEL_2\": \"positive\"}\n",
        "\n",
        "USE_HF_DATASET = True  # set False to use tweets.csv fallback"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289dcac3",
      "metadata": {},
      "source": [
        "### Step 2 - Load a dataset from Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "9575ae14",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user That's coming, but I think the vic...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text    label\n",
              "0  @user @user what do these '1/2 naked pics' hav...  neutral\n",
              "1  OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...  neutral\n",
              "2  @user @user That's coming, but I think the vic...  neutral"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if USE_HF_DATASET:\n",
        "    ds = load_dataset(\"cardiffnlp/tweet_eval\", \"sentiment\")\n",
        "    df = pd.DataFrame(ds[\"test\"]).head(500).copy()\n",
        "    df[\"label\"] = df[\"label\"].map(ID2LABEL)\n",
        "else:\n",
        "    df = pd.read_csv(\"tweets.csv\")\n",
        "    # Ensure it has 'text' and 'label' columns\n",
        "    df = df.rename(columns={c: c.strip() for c in df.columns})\n",
        "    assert {\"text\",\"label\"}.issubset(df.columns), \"tweets.csv must include text,label\"\n",
        "    df[\"label\"] = df[\"label\"].astype(str).str.lower()\n",
        "\n",
        "df = df[[\"text\",\"label\"]].dropna().reset_index(drop=True)\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db0546f1",
      "metadata": {},
      "source": [
        "### Step 3 - Define Failure-Relevant Metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "089146d4",
      "metadata": {},
      "source": [
        "In this step, you will create **at least 5** metadata columns that help you slice and analyze model behavior in Weights & Biases (W&B).\n",
        "These metadata columns should **capture meaningful properties of the data or model behavior that may influence performance**.\n",
        "\n",
        "Hypothesis-driven slices used below:\n",
        "1. **Hashtags** (`has_hashtag`): topic or meme tags can shift sentiment and context.\n",
        "2. **Mentions** (`has_mention`): conversational tweets may be short/ambiguous.\n",
        "3. **Negation** (`has_negation`): polarity flips can confuse models (e.g., ‚Äúnot good‚Äù).\n",
        "4. **Emoji density** (`emoji_dense`): emojis can signal sentiment not in text.\n",
        "5. **Unusual length** (`length_bucket`): very short or long tweets may be harder to parse.\n",
        "6. **URLs** (`has_url`): links reduce sentiment cues and add noise.\n",
        "\n",
        "Each metadata column corresponds to a hypothesis about when or why a model might succeed or fail.\n",
        "These columns will be propagated through inference and included in the final predictions_table logged to W&B."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62499536",
      "metadata": {},
      "source": [
        "After inference, your W&B table (df_long) will contain:\n",
        "- The original tweet text\n",
        "- Ground-truth sentiment labels\n",
        "- Model predictions and confidence scores\n",
        "- All metadata columns you defined for slicing\n",
        "\n",
        "You will use these metadata fields in the W&B UI (via the ‚ûï Filter option) to:\n",
        "- Create slices of the data\n",
        "- Compare model behavior across slices\n",
        "- Identify patterns, weaknesses, or regressions that are not visible in overall accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "3fd5775b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jrzem\\AppData\\Local\\Temp\\ipykernel_47460\\1975077457.py:15: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  df[\"has_negation\"] = df[\"text\"].str.contains(r\"\\b(not|never|no|can't|won't|isn't|don't|didn't)\\b\", regex=True)\n"
          ]
        }
      ],
      "source": [
        "# Step 3 ‚Äì Add slicing metadata (text-only)\n",
        "\n",
        "# Hypothesis-driven metadata columns\n",
        "import regex as re2\n",
        "\n",
        "def count_emojis(text: str) -> int:\n",
        "    return sum(ch in emoji.EMOJI_DATA for ch in str(text))\n",
        "\n",
        "# Base metadata\n",
        "text_len = df[\"text\"].str.len()\n",
        "\n",
        "df[\"emoji_count\"] = df[\"text\"].apply(count_emojis).astype(int)\n",
        "df[\"has_hashtag\"] = df[\"text\"].str.contains(r\"#\\w+\", regex=True)\n",
        "df[\"has_mention\"] = df[\"text\"].str.contains(r\"@\\w+\", regex=True)\n",
        "df[\"has_negation\"] = df[\"text\"].str.contains(r\"\\b(not|never|no|can't|won't|isn't|don't|didn't)\\b\", regex=True)\n",
        "df[\"has_url\"] = df[\"text\"].str.contains(r\"https?://|www\\.\", regex=True)\n",
        "\n",
        "# Length buckets (unusual short/long)\n",
        "df[\"length_bucket\"] = pd.cut(\n",
        "    text_len,\n",
        "    bins=[0, 30, 80, 140, 1000, 10_000],\n",
        "    labels=[\"0-30\", \"31-80\", \"81-140\", \"141-1000\", \"1001+\"],\n",
        "    include_lowest=True\n",
        ").astype(str)\n",
        "\n",
        "# Emoji density slice (emojis per 100 chars)\n",
        "df[\"emoji_density\"] = (df[\"emoji_count\"] / text_len.replace(0, 1)) * 100\n",
        "\n",
        "df[\"emoji_dense\"] = df[\"emoji_density\"] >= 4\n",
        "\n",
        "# Slice definitions for analysis\n",
        "# (At least five hypothesis-driven slices)\n",
        "def get_slices(df_any: pd.DataFrame):\n",
        "    return {\n",
        "        \"has_hashtag\": df_any[\"has_hashtag\"] == True,\n",
        "        \"has_mention\": df_any[\"has_mention\"] == True,\n",
        "        \"has_negation\": df_any[\"has_negation\"] == True,\n",
        "        \"emoji_dense\": df_any[\"emoji_dense\"] == True,\n",
        "        \"short_tweets\": df_any[\"length_bucket\"].astype(str).isin([\"0-30\"]),\n",
        "        \"long_tweets\": df_any[\"length_bucket\"].astype(str).isin([\"141-1000\", \"1001+\"]),\n",
        "        \"has_url\": df_any[\"has_url\"] == True,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e3a75f9d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch: 2.10.0+cpu\n",
            "transformers: 5.1.0\n",
            "CUDA available: False\n",
            "Python: c:\\Users\\jrzem\\OneDrive\\Semester Classwork\\Graduate\\Spring 2026 CMU\\Machine Learning in Production AI Engineering\\Labs\\mlip-model-testing-lab-4\\cmu-mlip-model-testing-lab\\.venv\\Scripts\\python.exe\n"
          ]
        }
      ],
      "source": [
        "# Transformers requires a backend (PyTorch/TensorFlow/Flax). We'll use PyTorch.\n",
        "try:\n",
        "    import torch, transformers, sys\n",
        "    print(\"torch:\", torch.__version__)\n",
        "    print(\"transformers:\", transformers.__version__)\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    print(\"Python:\", sys.executable)\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"Install PyTorch before proceeding: pip install torch torchvision torchaudio\") from e"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e85ec371",
      "metadata": {},
      "source": [
        "###  Step 4 ‚Äì Run Inference (Two Models)\n",
        "\n",
        "In this step, you'll use two HuggingFace sentiment analysis models to run inference on your dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "89f69d93",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [00:00<00:00, 1164.52it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
            "\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
            "Key                             | Status     |  | \n",
            "--------------------------------+------------+--+-\n",
            "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
            "roberta.pooler.dense.bias       | UNEXPECTED |  | \n",
            "roberta.pooler.dense.weight     | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "Infer: cardiffnlp/twitter-roberta-base-sentiment-latest: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:16<00:00, 30.87it/s]\n",
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 149/149 [00:00<00:00, 1186.14it/s, Materializing param=transformer.wte.weight]             \n",
            "\u001b[1mGPT2ForSequenceClassification LOAD REPORT\u001b[0m from: LYTinn/finetuning-sentiment-model-tweet-gpt2\n",
            "Key                                     | Status     |  | \n",
            "----------------------------------------+------------+--+-\n",
            "transformer.h.{0...11}.attn.bias        | UNEXPECTED |  | \n",
            "transformer.h.{0...11}.attn.masked_bias | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "Infer: LYTinn/finetuning-sentiment-model-tweet-gpt2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:19<00:00, 25.75it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>emoji_count</th>\n",
              "      <th>has_hashtag</th>\n",
              "      <th>has_mention</th>\n",
              "      <th>has_negation</th>\n",
              "      <th>has_url</th>\n",
              "      <th>length_bucket</th>\n",
              "      <th>emoji_density</th>\n",
              "      <th>emoji_dense</th>\n",
              "      <th>model</th>\n",
              "      <th>pred</th>\n",
              "      <th>conf</th>\n",
              "      <th>ex_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>81-140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.804726</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>31-80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.866949</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@user @user That's coming, but I think the vic...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>81-140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.763724</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I think I may be finally in with the in crowd ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>81-140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.774047</td>\n",
              "      <td>305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>81-140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.416397</td>\n",
              "      <td>160</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     label  emoji_count  \\\n",
              "0  @user @user what do these '1/2 naked pics' hav...   neutral            0   \n",
              "1  OH: ‚ÄúI had a blue penis while I was this‚Äù [pla...   neutral            0   \n",
              "2  @user @user That's coming, but I think the vic...   neutral            0   \n",
              "3  I think I may be finally in with the in crowd ...  positive            0   \n",
              "4  @user Wow,first Hugo Chavez and now Fidel Cast...  negative            0   \n",
              "\n",
              "   has_hashtag  has_mention  has_negation  has_url length_bucket  \\\n",
              "0        False         True          True    False        81-140   \n",
              "1        False        False         False    False         31-80   \n",
              "2        False         True         False    False        81-140   \n",
              "3         True         True         False    False        81-140   \n",
              "4        False         True         False    False        81-140   \n",
              "\n",
              "   emoji_density  emoji_dense           model      pred      conf  ex_id  \n",
              "0            0.0        False  baseline_model  negative  0.804726    113  \n",
              "1            0.0        False  baseline_model   neutral  0.866949    363  \n",
              "2            0.0        False  baseline_model   neutral  0.763724    102  \n",
              "3            0.0        False  baseline_model  positive  0.774047    305  \n",
              "4            0.0        False  baseline_model   neutral  0.416397    160  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def run_pipeline(model_id: str, texts: list[str]):\n",
        "    clf = pipeline(\n",
        "        \"text-classification\",\n",
        "        model=model_id,\n",
        "        truncation=True,\n",
        "        max_length=128,     # avoid truncation warnings\n",
        "        framework=\"pt\",\n",
        "        device=-1           # CPU\n",
        "    )\n",
        "    # (Optional) sanity check label mapping for this model\n",
        "    # print(model_id, clf.model.config.id2label)\n",
        "\n",
        "    preds, confs = [], []\n",
        "    for t in tqdm(texts, desc=f\"Infer: {model_id}\"):\n",
        "        out = clf(t)[0]\n",
        "        lbl = HF_LABEL_MAP.get(out[\"label\"], out[\"label\"])\n",
        "        preds.append(lbl)\n",
        "        confs.append(float(out[\"score\"]))\n",
        "    return preds, confs\n",
        "\n",
        "pred_frames = []\n",
        "texts = df[\"text\"].tolist()\n",
        "\n",
        "for model_name, model_id in MODELS.items():\n",
        "    yhat, conf = run_pipeline(model_id, texts)\n",
        "    tmp = df.copy()\n",
        "    tmp[\"model\"] = model_name\n",
        "    tmp[\"pred\"] = yhat\n",
        "    tmp[\"conf\"] = conf\n",
        "    pred_frames.append(tmp)\n",
        "\n",
        "df_long = pd.concat(pred_frames, ignore_index=True)\n",
        "\n",
        "# Add a stable example id so reshaping won't silently drop duplicates\n",
        "df_long[\"ex_id\"] = df_long.groupby([\"text\", \"label\"]).ngroup()\n",
        "\n",
        "df_long.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "d189f1a3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ex_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>emoji_count</th>\n",
              "      <th>emoji_density</th>\n",
              "      <th>emoji_dense</th>\n",
              "      <th>has_hashtag</th>\n",
              "      <th>has_mention</th>\n",
              "      <th>has_negation</th>\n",
              "      <th>has_url</th>\n",
              "      <th>length_bucket</th>\n",
              "      <th>conf_baseline_model</th>\n",
              "      <th>conf_candidate_model</th>\n",
              "      <th>pred_baseline_model</th>\n",
              "      <th>pred_candidate_model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\"Fatty Kim The Third\" üò≠üò≠üò≠</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0-30</td>\n",
              "      <td>0.486252</td>\n",
              "      <td>0.978987</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\"Focusing on [alt rightists'] respectability.....</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>81-140</td>\n",
              "      <td>0.573571</td>\n",
              "      <td>0.999728</td>\n",
              "      <td>negative</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>\"Kim Fatty the Third\"</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0-30</td>\n",
              "      <td>0.849732</td>\n",
              "      <td>0.937709</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\"We have lost everything\": Syrians return to r...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>81-140</td>\n",
              "      <td>0.751955</td>\n",
              "      <td>0.994244</td>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"who's the most wiped out white boy? Zac Efron...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>31-80</td>\n",
              "      <td>0.561232</td>\n",
              "      <td>0.906540</td>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ex_id                                               text     label  \\\n",
              "0      0                          \"Fatty Kim The Third\" üò≠üò≠üò≠   neutral   \n",
              "1      1  \"Focusing on [alt rightists'] respectability.....   neutral   \n",
              "2      2                              \"Kim Fatty the Third\"  negative   \n",
              "3      3  \"We have lost everything\": Syrians return to r...   neutral   \n",
              "4      4  \"who's the most wiped out white boy? Zac Efron...   neutral   \n",
              "\n",
              "   emoji_count  emoji_density  emoji_dense  has_hashtag  has_mention  \\\n",
              "0            3           12.0         True        False        False   \n",
              "1            0            0.0        False        False        False   \n",
              "2            0            0.0        False        False        False   \n",
              "3            0            0.0        False         True         True   \n",
              "4            0            0.0        False        False        False   \n",
              "\n",
              "   has_negation  has_url length_bucket  conf_baseline_model  \\\n",
              "0         False    False          0-30             0.486252   \n",
              "1         False    False        81-140             0.573571   \n",
              "2         False    False          0-30             0.849732   \n",
              "3         False    False        81-140             0.751955   \n",
              "4         False    False         31-80             0.561232   \n",
              "\n",
              "   conf_candidate_model pred_baseline_model pred_candidate_model  \n",
              "0              0.978987             neutral              neutral  \n",
              "1              0.999728            negative              neutral  \n",
              "2              0.937709             neutral              neutral  \n",
              "3              0.994244            negative             positive  \n",
              "4              0.906540             neutral             positive  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 4.5 ‚Äì Wide-format Table for Model Comparison (Optional but recommended)\n",
        "# One row per tweet, with baseline + candidate predictions in columns\n",
        "# Updated with custom metadata\n",
        "\n",
        "df_wide = df_long.pivot_table(\n",
        "    index=[\n",
        "        \"ex_id\", \"text\", \"label\",\n",
        "        \"emoji_count\", \"emoji_density\", \"emoji_dense\",\n",
        "        \"has_hashtag\", \"has_mention\", \"has_negation\", \"has_url\",\n",
        "        \"length_bucket\"\n",
        "    ],\n",
        "    columns=\"model\",\n",
        "    values=[\"pred\", \"conf\"],\n",
        "    aggfunc=\"first\"\n",
        ").reset_index()\n",
        "\n",
        "# Flatten column names (e.g., pred_baseline_model, conf_candidate_model)\n",
        "df_wide.columns = [\"_\".join([c for c in col if c]).strip(\"_\") for col in df_wide.columns]\n",
        "\n",
        "df_wide.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60dedaa9",
      "metadata": {},
      "source": [
        "### Step 5: Compute Metrics (Accuracy + Slice Accuracy + Regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "b77d0e90",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metrics for overall + slice accuracy\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_accuracy(y_true, y_pred):\n",
        "    return accuracy_score(list(y_true), list(y_pred))\n",
        "\n",
        "# Overall accuracy by model (df_long: one row per (tweet, model))\n",
        "overall = df_long.groupby(\"model\").apply(\n",
        "    lambda g: compute_accuracy(g[\"label\"], g[\"pred\"]),\n",
        "    include_groups=False\n",
        ")\n",
        "\n",
        "# Slice accuracy table (uses df_long masks)\n",
        "slice_table = wandb.Table(columns=[\"slice\", \"model\", \"accuracy\"])\n",
        "slice_metrics = {}\n",
        "\n",
        "for slice_name, mask in get_slices(df_long).items():\n",
        "    slice_metrics[slice_name] = {}\n",
        "    for model_name, g in df_long[mask].groupby(\"model\"):\n",
        "        acc = float(compute_accuracy(g[\"label\"], g[\"pred\"]))\n",
        "        slice_table.add_data(slice_name, model_name, acc)\n",
        "        slice_metrics[slice_name][model_name] = acc\n",
        "\n",
        "slice_metrics_df = (\n",
        "    pd.DataFrame(slice_metrics)\n",
        "    .T\n",
        "    .reset_index()\n",
        "    .rename(columns={\"index\": \"slice\"})\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "596b544f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regression rate: 0.408\n",
            "Improvement rate: 0.108\n",
            "Confident regression rate: 0.382\n"
          ]
        }
      ],
      "source": [
        "# Regression-aware evaluation (df_eval: one row per tweet, both model outputs) \n",
        "# A regression is when the candidate gets something wrong that the baseline got right.\n",
        "BASELINE = \"baseline_model\"\n",
        "CANDIDATE = \"candidate_model\"\n",
        "\n",
        "# Ensure ex_id exists (safe even if it already exists)\n",
        "df_long = df_long.copy()\n",
        "if \"ex_id\" not in df_long.columns:\n",
        "    df_long[\"ex_id\"] = df_long.groupby([\"text\", \"label\"]).ngroup()\n",
        "\n",
        "# Build df_eval with metadata carried through\n",
        "df_eval = (\n",
        "    df_long.pivot_table(\n",
        "        index=[\n",
        "            \"ex_id\", \"text\", \"label\",\n",
        "            \"emoji_count\", \"emoji_density\", \"emoji_dense\",\n",
        "            \"has_hashtag\", \"has_mention\", \"has_negation\", \"has_url\",\n",
        "            \"length_bucket\"\n",
        "        ],\n",
        "        columns=\"model\",\n",
        "        values=[\"pred\", \"conf\"],\n",
        "        aggfunc=\"first\"\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Flatten column names (pred_baseline_model, conf_candidate_model, etc.)\n",
        "df_eval.columns = [\"_\".join([c for c in col if c]).strip(\"_\") for col in df_eval.columns]\n",
        "\n",
        "# Correctness flags\n",
        "df_eval[\"baseline_correct\"]  = df_eval[f\"pred_{BASELINE}\"] == df_eval[\"label\"]\n",
        "df_eval[\"candidate_correct\"] = df_eval[f\"pred_{CANDIDATE}\"] == df_eval[\"label\"]\n",
        "\n",
        "# Regression / improvement flags\n",
        "df_eval[\"regressed\"]   = df_eval[\"baseline_correct\"] & ~df_eval[\"candidate_correct\"]\n",
        "df_eval[\"improved\"]    = ~df_eval[\"baseline_correct\"] & df_eval[\"candidate_correct\"]\n",
        "df_eval[\"both_wrong\"]  = ~df_eval[\"baseline_correct\"] & ~df_eval[\"candidate_correct\"]\n",
        "df_eval[\"both_correct\"]= df_eval[\"baseline_correct\"] & df_eval[\"candidate_correct\"]\n",
        "\n",
        "# Confidence-conditional regression (candidate is confident AND worse than baseline)\n",
        "df_eval[\"confident_regression\"] = df_eval[\"regressed\"] & (df_eval[f\"conf_{CANDIDATE}\"] >= 0.8)\n",
        "\n",
        "# Global regression metrics\n",
        "regression_rate = float(df_eval[\"regressed\"].mean())\n",
        "improvement_rate = float(df_eval[\"improved\"].mean())\n",
        "conf_reg_rate = float(df_eval[\"confident_regression\"].mean())\n",
        "\n",
        "print(\"Regression rate:\", regression_rate)\n",
        "print(\"Improvement rate:\", improvement_rate)\n",
        "print(\"Confident regression rate:\", conf_reg_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "12e21e2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Slice-level regression metrics\n",
        "\n",
        "# Define slices on df_eval (must use columns that exist in df_eval)\n",
        "def get_slices_eval(df_any):\n",
        "    return {\n",
        "        \"has_hashtag\": df_any[\"has_hashtag\"] == True,\n",
        "        \"has_mention\": df_any[\"has_mention\"] == True,\n",
        "        \"has_negation\": df_any[\"has_negation\"] == True,\n",
        "        \"emoji_dense\": df_any[\"emoji_dense\"] == True,\n",
        "        \"short_tweets\": df_any[\"length_bucket\"].astype(str).isin([\"0-30\"]),\n",
        "        \"long_tweets\": df_any[\"length_bucket\"].astype(str).isin([\"141-1000\", \"1001+\"]),\n",
        "        \"has_url\": df_any[\"has_url\"] == True,\n",
        "    }\n",
        "\n",
        "# Slice-level regression metrics table\n",
        "reg_table = wandb.Table(columns=[\"slice\", \"metric\", \"value\"])\n",
        "reg_metrics = {}\n",
        "\n",
        "for slice_name, mask in get_slices_eval(df_eval).items():\n",
        "    g = df_eval[mask]\n",
        "    if len(g) == 0:\n",
        "        continue\n",
        "\n",
        "    reg = float(g[\"regressed\"].mean())\n",
        "    imp = float(g[\"improved\"].mean())\n",
        "    conf_reg = float(g[\"confident_regression\"].mean())\n",
        "\n",
        "    reg_table.add_data(slice_name, \"regression_rate\", reg)\n",
        "    reg_table.add_data(slice_name, \"improvement_rate\", imp)\n",
        "    reg_table.add_data(slice_name, \"confident_regression_rate\", conf_reg)\n",
        "\n",
        "    reg_metrics[slice_name] = {\n",
        "        \"regression_rate\": reg,\n",
        "        \"improvement_rate\": imp,\n",
        "        \"conf_reg_rate\": conf_reg\n",
        "    }\n",
        "\n",
        "regression_metrics_df = (\n",
        "    pd.DataFrame(reg_metrics)\n",
        "    .T\n",
        "    .reset_index()\n",
        "    .rename(columns={\"index\": \"slice\"})\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e7843a",
      "metadata": {},
      "source": [
        "# Step 6 ‚Äî #TODO: Log to W&B & Analyse Slices\n",
        "# (Make sure PROJECT/ENTITY/RUN_NAME exist from Step 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "425dd4ea",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\jrzem\\OneDrive\\Semester Classwork\\Graduate\\Spring 2026 CMU\\Machine Learning in Production AI Engineering\\Labs\\mlip-model-testing-lab-4\\cmu-mlip-model-testing-lab\\wandb\\run-20260206_114322-jdkrufoi</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/jdkrufoi' target=\"_blank\">baseline_vs_candidate</a></strong> to <a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026' target=\"_blank\">https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/jdkrufoi' target=\"_blank\">https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/jdkrufoi</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W&B run URL: https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/jdkrufoi\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>baseline_model_accuracy</td><td>0.698</td></tr><tr><td>candidate_model_accuracy</td><td>0.398</td></tr><tr><td>confident_regression_rate</td><td>0.382</td></tr><tr><td>improvement_rate</td><td>0.108</td></tr><tr><td>regression_rate</td><td>0.408</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">baseline_vs_candidate</strong> at: <a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/jdkrufoi' target=\"_blank\">https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/jdkrufoi</a><br> View project at: <a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026' target=\"_blank\">https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026</a><br>Synced 4 W&B file(s), 7 media file(s), 14 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20260206_114322-jdkrufoi\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 6: Log to W&B\n",
        "\n",
        "PROJECT = \"mlip-lab4-slices-2026\"\n",
        "ENTITY = None\n",
        "RUN_NAME = \"baseline_vs_candidate\"\n",
        "run = wandb.init(project=PROJECT, entity=ENTITY, name=RUN_NAME)\n",
        "\n",
        "# Required dataframes\n",
        "wandb.log({\"df_long\": wandb.Table(dataframe=df_long)})\n",
        "wandb.log({\"slice_metrics\": wandb.Table(dataframe=slice_metrics_df)})\n",
        "wandb.log({\"regression_metrics\": wandb.Table(dataframe=regression_metrics_df)})\n",
        "wandb.log({\"df_eval\": wandb.Table(dataframe=df_eval)})\n",
        "\n",
        "# Also log the prebuilt tables for easy charting\n",
        "wandb.log({\"predictions_table\": wandb.Table(dataframe=df_long)})\n",
        "wandb.log({\"slice_table\": slice_table})\n",
        "wandb.log({\"regression_table\": reg_table})\n",
        "\n",
        "for model_name, acc in overall.items():\n",
        "    wandb.summary[f\"{model_name}_accuracy\"] = float(acc)\n",
        "wandb.summary[\"regression_rate\"] = regression_rate\n",
        "wandb.summary[\"improvement_rate\"] = improvement_rate\n",
        "wandb.summary[\"confident_regression_rate\"] = conf_reg_rate\n",
        "\n",
        "print(\"W&B run URL:\", run.get_url())\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "599c3b74",
      "metadata": {},
      "source": [
        "### Instructions: Exploring Slice-Based Evaluation in W&B\n",
        "\n",
        "# Purpose\n",
        "In this lab, you are evaluating a candidate sentiment model to decide whether it should replace an existing baseline (production) model.\n",
        "You have already:\n",
        "  - run both models on the same dataset\n",
        "  - logged predictions, confidence scores, and metadata to W&B\n",
        "  - created metadata that allows you to slice the data\n",
        "The most important goal is to understand when and why models behave differently.\n",
        "Overall accuracy alone is often misleading.\n",
        "\n",
        "# What to do in W&B\n",
        "1. Open your W&B run\n",
        "  - Click the project link and open the latest run.\n",
        "2. Explore the predictions table\n",
        "  - Go to the Tables tab and open predictions_table.\n",
        "  - Each row is one tweet √ó one model.\n",
        "3. Create and analyze slices (most important)\n",
        "  - Use filters to create meaningful slices \n",
        "    (e.g., negation, emojis, hashtags, long tweets).\n",
        "  - For each slice:\n",
        "    - Compare baseline vs candidate performance.\n",
        "    - Compare slice accuracy to overall accuracy.\n",
        "    - Inspect a few misclassified examples to identify patterns.\n",
        "4. Visualize slice performance\n",
        "  - Open slice_metrics.\n",
        "  - Create bar charts comparing baseline vs candidate accuracy for at least two slices.\n",
        "5. Discuss your findings with the TA\n",
        "  - Explain why slicing reveals issues that overall accuracy hides.\n",
        "  - Say whether the candidate model should be deployed and why.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "41f83c2f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hashtags: topic tags can change context; accur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mentions: conversational tweets are often shor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Negation: polarity flips (e.g., ‚Äònot good‚Äô) ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Emoji-dense: emojis often carry sentiment not ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Short tweets: very short text can be too spars...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Long tweets: longer tweets may contain mixed s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>URLs: link-heavy tweets reduce explicit sentim...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0\n",
              "0  Hashtags: topic tags can change context; accur...\n",
              "1  Mentions: conversational tweets are often shor...\n",
              "2  Negation: polarity flips (e.g., ‚Äònot good‚Äô) ar...\n",
              "3  Emoji-dense: emojis often carry sentiment not ...\n",
              "4  Short tweets: very short text can be too spars...\n",
              "5  Long tweets: longer tweets may contain mixed s...\n",
              "6  URLs: link-heavy tweets reduce explicit sentim..."
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Students: replace the placeholders below with 1‚Äì2 sentence insights\n",
        "saved_slice_notes = [\n",
        "    \"Hashtags: topic tags can change context; accuracy may drift on meme or event tags.\",\n",
        "    \"Mentions: conversational tweets are often short and ambiguous, which can reduce sentiment clarity.\",\n",
        "    \"Negation: polarity flips (e.g., ‚Äònot good‚Äô) are common failure modes for sentiment models.\",\n",
        "    \"Emoji-dense: emojis often carry sentiment not stated in text, so misreads can spike.\",\n",
        "    \"Short tweets: very short text can be too sparse for reliable sentiment.\",\n",
        "    \"Long tweets: longer tweets may contain mixed sentiment and confuse single-label models.\",\n",
        "    \"URLs: link-heavy tweets reduce explicit sentiment cues and add noise.\",\n",
        "]\n",
        "\n",
        "pd.DataFrame(saved_slice_notes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7aa906c",
      "metadata": {},
      "source": [
        "### Step 7 - Targeted stress testing with LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c396331d",
      "metadata": {},
      "source": [
        "TODO: \n",
        "In this step, you will use a Large Language Model (LLM) to generate test cases that specifically target a weakness you observed during slicing.\n",
        "\n",
        "What to do:\n",
        "1. Choose one slice where you noticed poor performance, regressions, or surprising behavior.\n",
        "2. Write a short hypothesis (1‚Äì2 sentences) explaining why the model might struggle on this slice. Example:\n",
        "‚ÄúThe model struggles with tweets that use slang and sarcasm.‚Äù\n",
        "3. Use an LLM to generate 10 test cases designed to test this hypothesis.\n",
        "These can include:\n",
        "    - subtle or ambiguous cases\n",
        "    - difficult or adversarial cases\n",
        "    - small wording changes that affect sentiment\n",
        "4. Re-run both models on the generated test cases (helper script given below.)\n",
        "5. Briefly describe what you observed to the TA:\n",
        "    - Did the same failures appear again?\n",
        "    - notice any new failure patterns?\n",
        "    - would this affect your confidence in deploying the model?\n",
        "\n",
        "Your input can be in the following format:\n",
        "\n",
        "> Examples:\n",
        "> - @user @user That‚Äôs coming, but I think the victims are going to be Medicaid recipients.\n",
        "> - I think I may be finally in with the in crowd #mannequinchallenge  #grads2014 @user\n",
        "> \n",
        "> Generate more tweets using slangs.\n",
        "\n",
        "Use our provided GPTs to start the task: [llm-based-test-case-generator](https://chatgpt.com/g/g-982cylVn2-llm-based-test-case-generator). If you do not have access to GPTs, use the plain ChatGPT or other LLM providers you have access to instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "49623362",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Paste your 10 generated tweets here:\n",
        "generated_slice_description = (\n",
        "    \"Weak slice selected: negation. Hypothesis: models struggle to flip polarity when negation \"\n",
        "    \"(not/never/don‚Äôt/ can‚Äôt) appears near sentiment words.\"\n",
        ")\n",
        "\n",
        "generated_cases = [\n",
        "    \"This is not good at all.\",\n",
        "    \"I don't love this update, honestly.\",\n",
        "    \"Not bad, but not great either.\",\n",
        "    \"I can't say I'm happy with this service.\",\n",
        "    \"Never thought I'd dislike this feature so much.\",\n",
        "    \"I don't hate it, but I don't like it either.\",\n",
        "    \"This is not the worst, but it's not fine.\",\n",
        "    \"I didn't enjoy that experience.\",\n",
        "    \"I'm not excited about the changes.\",\n",
        "    \"Not impressed by the new design.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "2ce7deec",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Helper code to run models on synthetic test cases:\n",
        "\n",
        "def run_on_generated_tests(texts, models=MODELS):\n",
        "    rows = []\n",
        "    for model_name, model_id in models.items():\n",
        "        clf = pipeline(\n",
        "            \"text-classification\",\n",
        "            model=model_id,\n",
        "            truncation=True,\n",
        "            framework=\"pt\",\n",
        "            device=-1\n",
        "        )\n",
        "        for t in texts:\n",
        "            out = clf(t)[0]\n",
        "            rows.append({\n",
        "                \"text\": t,\n",
        "                \"model\": model_name,\n",
        "                \"pred\": HF_LABEL_MAP.get(out[\"label\"], out[\"label\"]),\n",
        "                \"conf\": float(out[\"score\"])\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "f4a55969",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 201/201 [00:00<00:00, 848.08it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
            "\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
            "Key                             | Status     |  | \n",
            "--------------------------------+------------+--+-\n",
            "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
            "roberta.pooler.dense.bias       | UNEXPECTED |  | \n",
            "roberta.pooler.dense.weight     | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 149/149 [00:00<00:00, 1211.36it/s, Materializing param=transformer.wte.weight]             \n",
            "\u001b[1mGPT2ForSequenceClassification LOAD REPORT\u001b[0m from: LYTinn/finetuning-sentiment-model-tweet-gpt2\n",
            "Key                                     | Status     |  | \n",
            "----------------------------------------+------------+--+-\n",
            "transformer.h.{0...11}.attn.bias        | UNEXPECTED |  | \n",
            "transformer.h.{0...11}.attn.masked_bias | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>model</th>\n",
              "      <th>pred</th>\n",
              "      <th>conf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is not good at all.</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.924885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I don't love this update, honestly.</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.940950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not bad, but not great either.</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.767315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I can't say I'm happy with this service.</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.733696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Never thought I'd dislike this feature so much.</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.907429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I don't hate it, but I don't like it either.</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.793088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>This is not the worst, but it's not fine.</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.877530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I didn't enjoy that experience.</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.900324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>I'm not excited about the changes.</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.836788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Not impressed by the new design.</td>\n",
              "      <td>baseline_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.869310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>This is not good at all.</td>\n",
              "      <td>candidate_model</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.480448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I don't love this update, honestly.</td>\n",
              "      <td>candidate_model</td>\n",
              "      <td>positive</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Not bad, but not great either.</td>\n",
              "      <td>candidate_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.999682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I can't say I'm happy with this service.</td>\n",
              "      <td>candidate_model</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.999950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Never thought I'd dislike this feature so much.</td>\n",
              "      <td>candidate_model</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.887849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I don't hate it, but I don't like it either.</td>\n",
              "      <td>candidate_model</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.732446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>This is not the worst, but it's not fine.</td>\n",
              "      <td>candidate_model</td>\n",
              "      <td>negative</td>\n",
              "      <td>0.994403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>I didn't enjoy that experience.</td>\n",
              "      <td>candidate_model</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.827824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I'm not excited about the changes.</td>\n",
              "      <td>candidate_model</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.996211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Not impressed by the new design.</td>\n",
              "      <td>candidate_model</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.999441</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               text            model  \\\n",
              "0                          This is not good at all.   baseline_model   \n",
              "1               I don't love this update, honestly.   baseline_model   \n",
              "2                    Not bad, but not great either.   baseline_model   \n",
              "3          I can't say I'm happy with this service.   baseline_model   \n",
              "4   Never thought I'd dislike this feature so much.   baseline_model   \n",
              "5      I don't hate it, but I don't like it either.   baseline_model   \n",
              "6         This is not the worst, but it's not fine.   baseline_model   \n",
              "7                   I didn't enjoy that experience.   baseline_model   \n",
              "8                I'm not excited about the changes.   baseline_model   \n",
              "9                  Not impressed by the new design.   baseline_model   \n",
              "10                         This is not good at all.  candidate_model   \n",
              "11              I don't love this update, honestly.  candidate_model   \n",
              "12                   Not bad, but not great either.  candidate_model   \n",
              "13         I can't say I'm happy with this service.  candidate_model   \n",
              "14  Never thought I'd dislike this feature so much.  candidate_model   \n",
              "15     I don't hate it, but I don't like it either.  candidate_model   \n",
              "16        This is not the worst, but it's not fine.  candidate_model   \n",
              "17                  I didn't enjoy that experience.  candidate_model   \n",
              "18               I'm not excited about the changes.  candidate_model   \n",
              "19                 Not impressed by the new design.  candidate_model   \n",
              "\n",
              "        pred      conf  \n",
              "0   negative  0.924885  \n",
              "1   negative  0.940950  \n",
              "2   negative  0.767315  \n",
              "3   negative  0.733696  \n",
              "4   negative  0.907429  \n",
              "5   negative  0.793088  \n",
              "6   negative  0.877530  \n",
              "7   negative  0.900324  \n",
              "8   negative  0.836788  \n",
              "9   negative  0.869310  \n",
              "10   neutral  0.480448  \n",
              "11  positive  1.000000  \n",
              "12  negative  0.999682  \n",
              "13  positive  0.999950  \n",
              "14   neutral  0.887849  \n",
              "15  positive  0.732446  \n",
              "16  negative  0.994403  \n",
              "17   neutral  0.827824  \n",
              "18  positive  0.996211  \n",
              "19   neutral  0.999441  "
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_df = run_on_generated_tests(generated_cases)\n",
        "generated_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "5752e207",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\jrzem\\OneDrive\\Semester Classwork\\Graduate\\Spring 2026 CMU\\Machine Learning in Production AI Engineering\\Labs\\mlip-model-testing-lab-4\\cmu-mlip-model-testing-lab\\wandb\\run-20260206_114331-rpwonj49</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rpwonj49' target=\"_blank\">baseline_vs_candidate_synthetic</a></strong> to <a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026' target=\"_blank\">https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rpwonj49' target=\"_blank\">https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rpwonj49</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">baseline_vs_candidate_synthetic</strong> at: <a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rpwonj49' target=\"_blank\">https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026/runs/rpwonj49</a><br> View project at: <a href='https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026' target=\"_blank\">https://wandb.ai/jzembowe-carnegie-mellon-university/mlip-lab4-slices-2026</a><br>Synced 4 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20260206_114331-rpwonj49\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# OPTIONAL: Log synthetic test cases to W&B\n",
        "run = wandb.init(project=PROJECT, entity=ENTITY, name=RUN_NAME + \"_synthetic\")\n",
        "wandb.log({\"synthetic_tests\": wandb.Table(dataframe=generated_df)})\n",
        "run.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
